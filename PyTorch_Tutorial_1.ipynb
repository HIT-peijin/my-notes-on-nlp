{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6oqGiIXvrMl"
   },
   "source": [
    "# BERT baseline课程：Pytorch快速入门\n",
    "\n",
    "### Author: Michael\n",
    "\n",
    "\n",
    "利用这个notebook，我带领大家对pytorch这个框架进行学习。\n",
    "\n",
    "大家同时可以参考： \n",
    "* Official PyTorch Documentation on [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) by Soumith Chintala\n",
    "* PyTorch Tutorial Notebook, [Build Basic Generative Adversarial Networks (GANs) | Coursera](https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans) by Sharon Zhou, offered on Coursera\n",
    "\n",
    "\n",
    "主要内容:\n",
    "\n",
    "1. tensor：\n",
    "1.1. tensor 初始化；\n",
    "1.2. tensor 的一些属性；\n",
    "1.3. tensor 的运算；\n",
    "\n",
    "2. torch.nn 初探\n",
    "2.1. 神经网络基本模块\n",
    "2.2. 利用nn.Module写更复杂\n",
    "\n",
    "3. torch.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gk1UKaNvrMv"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "[PyTorch](https://pytorch.org/)目前在学术界和工业界都有很广泛的应用。\n",
    "\n",
    "PyTorch相比于[TensorFlow](https://www.tensorflow.org/)要更加灵活，因为PyTorch允许用户在执行代码时定义操作，也就是动态图。而TensorFlow需要在执行操作之前定义静态图。\n",
    "\n",
    "目前，“TensorFlow”在业界更受欢迎，但“PyTorch”常常是研究人员首选的机器学习框架。\n",
    "\n",
    "\n",
    "我们现在来学习(或者复习)一下[PyTorch](https://pytorch.org/)的基础知识。首先，我们把它导入到notebook中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u0ukr7quvrMx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pprint, 让打印出来的内容更美观\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k10ZRdcBwDP3"
   },
   "source": [
    "We are all set to start our tutorial. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLdSN9ZXvrM0"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "张量(Tensors)是PyTorch中最基本的元素。张量类似于矩阵，但有一些额外的性质，他们可以代表高维度的数据。例如，两边有256个像素的图像可以用3x256x256张量表示，其中前3个维度表示颜色通道，红色、绿色和蓝色。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6aWvTEy7lgG"
   },
   "source": [
    "### Tensor 初始化\n",
    "\n",
    "有几种方法可以实例化“PyTorch”中的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c78_3AMEyvJd"
   },
   "source": [
    "#### **From a List**\n",
    "\n",
    "我们可以从一个python list初始化tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsjIW9I_ztiO",
    "outputId": "b78c8e03-211d-499b-9089-262f7ac04b19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从一个python list初始化tensor\n",
    "# sublist的长度需要统一\n",
    "data = [\n",
    "        [0, 1], \n",
    "        [2, 3],\n",
    "        [4, 5]\n",
    "       ]\n",
    "x_python = torch.tensor(data)\n",
    "\n",
    "# Print the tensor\n",
    "x_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 2 at dim 1 (got 1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-59835be718a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m        ]\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx_python\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Print the tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 1)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# bad case: 长度不统一\n",
    "data = [\n",
    "        [0, 1], \n",
    "        [2],\n",
    "        [4, 5]\n",
    "       ]\n",
    "x_python = torch.tensor(data)\n",
    "\n",
    "# Print the tensor\n",
    "x_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c276ab1d6632>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m        ]\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx_python\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Print the tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# bad case: 类型不支持\n",
    "data = [\n",
    "        [0, 1], \n",
    "        [2, \"aaa\"],\n",
    "        [4, 5]\n",
    "       ]\n",
    "x_python = torch.tensor(data)\n",
    "\n",
    "# Print the tensor\n",
    "x_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv6ZEoZ0RWb5"
   },
   "source": [
    "#### tensor类型\n",
    "\n",
    "torch.tensor()支持我们指定类型 dtype。 常见的类型包括： `torch.bool`, `torch.float`, and `torch.long`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bQF5IhsD7-n",
    "outputId": "a4729524-2b06-4545-cf1f-f83a5a7574b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定tensor的类型\n",
    "data = [\n",
    "        [0, 1], \n",
    "        [2, 3],\n",
    "        [4, 5]\n",
    "       ]\n",
    "x_float = torch.tensor(data, dtype=torch.float)\n",
    "x_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16VoILaaE-_j",
    "outputId": "8d236b7a-b60e-482c-c28b-df25925d7819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定tensor的类型为bool： 不为零为True\n",
    "x_bool = torch.tensor(data, dtype=torch.bool)\n",
    "x_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4HccPWFEQUB"
   },
   "source": [
    "可以用 `x.float()` 或者 `x.long()` 这样的写法来指定类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nh_yq0SuTS_W",
    "outputId": "f01ac372-5cb4-4be7-ae34-7c0a37b1b444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_python.float()  # not inplace: 原数据没有改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFiS1OFdTlKE"
   },
   "source": [
    "我们同样可以使用`tensor.FloatTensor`, `tensor.LongTensor`, `tensor.Tensor`。\n",
    "\n",
    "`tensor.LongTensor` 我们会用的很多，因为涉及编号的数据，都用这个。比如词在词汇表的编号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXXWZ1H2TkNN",
    "outputId": "66564be9-f6df-4fab-c248-724635a2e272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `torch.Tensor` 默认是 float\n",
    "# Same as torch.FloatTensor(data)\n",
    "x = torch.Tensor(data) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuLzDzsoytM2"
   },
   "source": [
    "#### **From a NumPy Array**\n",
    "从 `NumPy` array 初始化. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtSNe8X-2Pox",
    "outputId": "e0e2222c-27db-485f-a005-9ee3f6463e72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 初始化 from a NumPy array\n",
    "ndarray = np.array(data)\n",
    "# x_numpy = torch.from_numpy(ndarray)\n",
    "x_numpy = torch.FloatTensor(ndarray)\n",
    "\n",
    "# Print the tensor\n",
    "x_numpy.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhtcBgum3OZ3"
   },
   "source": [
    "#### **From a Tensor**\n",
    "通过以下方法，我们可以从一个torch tensor初始化另一个tensor:\n",
    "\n",
    "* `torch.ones_like(old_tensor)`: 初始化一个全为1的tensor.\n",
    "* `torch.zeros_like(old_tensor)`: 初始化一个全为0的tensor.\n",
    "* `torch.rand_like(old_tensor)`: 初始化一个tensor，每个元素都是从0-1的uniform 分布中采样得到.\n",
    "* `torch.randn_like(old_tensor)`: 初始化一个tensor，每个元素都是从标准正态分布中采样得到.\n",
    "\n",
    "新tensor会继承old_tensor的一些性质，比如shape，device；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoKVhcLh2yqe",
    "outputId": "8ed9acbe-947b-4890-db81-c83d802c0f86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原tensor\n",
    "x = torch.tensor([[1., 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FncfGN6z7ELA",
    "outputId": "71db6165-ea7a-4068-da13-c0310790c4b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化一个全为0的tensor\n",
    "x_zeros = torch.zeros_like(x)\n",
    "x_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D993dpnP6iA8",
    "outputId": "ca8a7fd3-e7d0-47f7-a7c0-1bddc5614223"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化一个全为1的tensor\n",
    "x_ones = torch.ones_like(x)\n",
    "x_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBUDeEm97IqW",
    "outputId": "455a2ce8-caf6-4252-c1be-6207e81d2649"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5996, 0.6581],\n",
       "        [0.5531, 0.0815]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化一个tensor，每个元素都是从0-1的uniform 分布中采样得到\n",
    "# between 0 and 1\n",
    "x_rand = torch.rand_like(x)\n",
    "x_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYsE3lKt7IEX",
    "outputId": "2c49ce88-937e-4afe-eb1c-37a625cbc77f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0096, -0.4681],\n",
       "        [ 0.2669, -0.4227]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化一个tensor，每个元素都是从标准正态分布中采样得到\n",
    "x_randn = torch.randn_like(x)\n",
    "x_randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6tqf7v38vbi"
   },
   "source": [
    "#### **By Specifying a Shape**\n",
    "\n",
    "指定形状初始化tensor\n",
    "\n",
    "方法我们已经见过类似的了:\n",
    "* `torch.zeros()`\n",
    "* `torch.ones()`\n",
    "* `torch.rand()`\n",
    "* `torch.randn()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dh4I4Npz-dZ4",
    "outputId": "e45a1095-0d18-4266-ceb7-a7c9de1f18e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape 通过tuple传入\n",
    "shape = (4, 2, 2)\n",
    "x_zeros = torch.zeros(shape) # x_zeros = torch.zeros(4, 3, 2) is an alternative\n",
    "x_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LEjeR24MLkN"
   },
   "source": [
    "#### **With `torch.arange()`**\n",
    "We can also create a tensor with `torch.arange(end)`, which returns a `1-D` tensor with elements ranging from `0` to `end-1`. We can use the optional `start` and `step` parameters to create tensors with different ranges.  \n",
    "\n",
    "我们也可以用torch.arange(end)；\n",
    "\n",
    "叫做arange，所以我们也能猜到是做啥的： a `1-D` tensor，元素是 ranging from `0` to `end-1`。\n",
    "\n",
    "同样，我们也可以用torch.arange(start, step, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EjARl2aM7pA",
    "outputId": "264a9ffa-5d05-4b9d-9901-cd49cbb93264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 元素从0-9的tensor\n",
    "x = torch.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 元素从3-9，间隔2的tensor\n",
    "x = torch.arange(3, 9, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgpkRn527zSr"
   },
   "source": [
    "### Tensor Properties\n",
    "\n",
    "Tensor有几个性质我们需要熟知；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBt6e4xZT3zr"
   },
   "source": [
    "#### Data Type\n",
    "\n",
    "`dtype` ： 数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlF3k3eUT_hQ",
    "outputId": "c2416faf-77cc-46e9-a22e-a67fe14bc13d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.dtype\n",
    "x = torch.ones(3, 2)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1vtN4Dy8FAG"
   },
   "source": [
    "#### Shape\n",
    "\n",
    "`shape`: 形状。告诉我们tensor有多少维，每个维度上面有几个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24gXLJcn7Pxs",
    "outputId": "ef11b998-9fc4-458e-8452-6d545da19694"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a 3x2 tensor, with 3 rows and 2 columns\n",
    "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# 也可以使用 x.size()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vV0cE1cXAEHP",
    "outputId": "1d12cf8d-c659-4127-807e-91459ba12d3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out its shape\n",
    "# Same as x.size()\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MA3vnJnaAQlc",
    "outputId": "cfa251e1-be1c-4dbc-9803-bc213ca05a2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拿到特定维度上的元素个数\n",
    "# 0th dimension corresponds to the rows\n",
    "x.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以使用x.size(0)\n",
    "x.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCQm7ToPOveH"
   },
   "source": [
    "用 `x.view()` 方法改变tensor形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1JH3fiNO5Gu",
    "outputId": "0c270810-811b-466f-a5d2-70f240942aa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.view()\n",
    "# x_view 和 x 指向同样的内存，所以对x_view做操作，也会改变x;\n",
    "x_view = x.view(2, 3)\n",
    "x_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3C3x4seqPGEI",
    "outputId": "66e48d01-5702-414c-c628-055adbdcdeef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用 -1： 让pytorch帮你算应该有多大的维数\n",
    "x_view = x.view(3, -1)\n",
    "x_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "only one dimension can be inferred",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-7fb3943cff7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# bad case: only one dimension can be inferred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_view\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_view\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: only one dimension can be inferred"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# bad case: only one dimension can be inferred\n",
    "x_view = x.view(3, -1, -1)\n",
    "x_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYSCEesPITpf"
   },
   "source": [
    "也可以使用`torch.reshape()`方法。但是可能会引入新的内存消耗(这里涉及到contiguous概念)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLGcGYE4Llom",
    "outputId": "e810557b-552f-4b0f-a37a-1924bec7fcfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  3x2 --> 2x3 \n",
    "x_reshaped = torch.reshape(x, (2, 3))\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWNTZKZZQ9i6"
   },
   "source": [
    "`torch.unsqueeze(x, dim)`： 添加一个维数为1的维度到dim维度\n",
    "\n",
    "`torch.squeeze(x)`： 去掉维数为1的维度；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_IYojrJRh-m",
    "outputId": "ed315529-ea33-4cbe-9878-4581f3afbcdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化一个tensor\n",
    "x = torch.arange(10).reshape(5, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLhg_oZ4SHh-",
    "outputId": "a32cf8a3-c1f4-4220-d948-b42fd12f8772"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new dimension of size 1 at the 1st dimension\n",
    "x = x.unsqueeze(1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoGYGbMRSo-J",
    "outputId": "9c8415c4-ebf3-40ab-9faa-b13c5fd42c62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze the dimensions of x by getting rid of all the dimensions with 1 element\n",
    "x = x.squeeze()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQpZ4556B3lb"
   },
   "source": [
    "`x.numel()`： 计算元素个数总量；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-irUWlxTB6a",
    "outputId": "c070c19a-cf0c-46cb-ec54-8254a9c83974"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算元素个数总量.\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_M1U_RTpBhl2"
   },
   "source": [
    "#### **Device**\n",
    "\n",
    "Device: 深度学习一个非常重要的性质；因为我们有时候需要写代码将tensor从cpu加载进入gpu，进行网络的训练；有的时候预测结果需要从gpu拿出来；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYRGhIbnCl3b",
    "outputId": "4eac92c3-48f5-4e4e-cdf1-329bd79538b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化一个tensor\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byEnJyKdBgjl",
    "outputId": "04440390-a16d-4250-920e-64dade75622a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印出device信息\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vqf_-NADFX8"
   },
   "source": [
    "`x.to(device)`: 将数据传到指定设备."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "GzA6zqkXDEt1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查是否有GPU设备\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  x.to('cuda') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7BMktFFAkRA"
   },
   "source": [
    "### Tensor Indexing\n",
    "\n",
    "tensor可以进行索引，与numpy相似；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRJN7ovWDsKV",
    "outputId": "f4bea081-d4c4-49a2-e529-fa502cf135f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an example tensor\n",
    "x = torch.Tensor([\n",
    "                  [[1, 2], [3, 4]],\n",
    "                  [[5, 6], [7, 8]], \n",
    "                  [[9, 10], [11, 12]] \n",
    "                 ])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M67ZiOF1Heyc",
    "outputId": "0821f0cc-5a93-46e6-bee4-9fd648723a27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guXKE7m8AX1K",
    "outputId": "cf492c27-a67d-4fbe-b57a-54fb4f8802a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一行\n",
    "x[0] # Equivalent to x[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8m8EyVvES4-"
   },
   "source": [
    "`:`： 该维度都取出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Z6GFUcuEL85",
    "outputId": "f36a740c-df12-42f6-a64b-d4b3038168f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 9.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 左上方的元素\n",
    "x[:, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm8vc3nuXaEw"
   },
   "source": [
    "We can also access arbitrary elements in each dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYhcH9gaWHyW",
    "outputId": "f900ea02-4f55-4af6-c485-c5dec4baf196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4xl6CW3RrEw",
    "outputId": "1cb93869-7764-4d22-b411-dcaadb906830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以使用torch tensor来进行indexing\n",
    "\n",
    "i = torch.tensor([0, 0, 1, 1])\n",
    "y = x[i]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3QYZ8k7Wvqp",
    "outputId": "6cb46909-2800-45a0-abb3-0707c2c50d6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 两个tensor来索引：\n",
    "# 有一个遍历的过程：x[1, 0], x[2, 0]\n",
    "i = torch.tensor([1, 2])\n",
    "j = torch.tensor([0])\n",
    "x[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 6.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 10.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAELXC--IHS7"
   },
   "source": [
    "We can get a `Python` scalar value from a tensor with `item()`. \n",
    "\n",
    "用`item()`把数据从tensor中取出为python标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BM-ZujN2IGaQ",
    "outputId": "785f43c3-5670-4fa2-ed51-e72e9c0474ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NwxK7d_Ycgs",
    "outputId": "343abf96-2d77-49b0-9076-c0f617e7aafe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GltnmDzeIXJM"
   },
   "source": [
    "### Operations\n",
    "\n",
    "运算： 与numpy非常相似；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9KBzcA0G6v9",
    "outputId": "057decb7-7a56-4fcc-bc20-781cba8d0caf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "x = torch.ones((3,2,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUw8MAHqKuzs",
    "outputId": "fd10173a-caf5-4e45-ceca-c0b32f4bf39e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise addition\n",
    "# `-`  for minus\n",
    "x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAfMsaz1Gw5v",
    "outputId": "d0432152-8137-46e7-902a-ec0b779d5471"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise multiplication\n",
    "# Use / for division\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aq89FU7OOe7"
   },
   "source": [
    "\n",
    "我们可以在大小兼容的不同张量之间应用上述的运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGhz62wILIfN",
    "outputId": "40f51f08-a80b-41b9-b9a1-e874c8b89e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 4x3 tensor of 6s\n",
    "a = torch.ones((4,3)) * 6\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvDC1OzzPyLV",
    "outputId": "291f0c1f-9a64-4c23-a399-7464c6cbd39e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 1D tensor of 2s\n",
    "b = torch.ones(3) * 2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUF9noMTP5NI",
    "outputId": "9cd9b5ab-c292-4987-c562-a3f8e4ec8a2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide a by b\n",
    "a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTiVVbukXRct"
   },
   "source": [
    "`tensor.matmul(other_tensor)`： matrix multiplication， 同时可以使用 `@`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPoC_WcbXCw5",
    "outputId": "332f95f5-11fd-431d-c77a-e4c98dbd6660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36., 36., 36., 36.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# a @ b.T returns the same result since b is 1D tensor and the 2nd dimension\n",
    "# is inferred\n",
    "a.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36., 36., 36., 36.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative to a.matmul(b)\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tensor.T`： matrix 转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2WEoQjVYBQ8",
    "outputId": "0f97c447-5f28-4483-ac82-e1b484663b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(a.shape)\n",
    "pp.pprint(a.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PibNpxbYYf2"
   },
   "source": [
    "#### 求和&求标准差\n",
    "\n",
    "`tensor.mean()`: 对所有维度求和；\n",
    "`tensor.mean(dim)`: 对指定维度求和；\n",
    "\n",
    "`tensor.std()`: \n",
    "`tensor.std(dim)`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a987teCtYg7R",
    "outputId": "0ca3799b-6dec-49ea-c1eb-d6265f390818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Mean: 2.5'\n",
      "'Mean in the 0th dimension: tensor([2.5000, 2.5000])'\n",
      "'Mean in the 1st dimension: tensor([1., 2., 3., 4.])'\n"
     ]
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "m = torch.tensor(\n",
    "    [\n",
    "     [1., 1.],\n",
    "     [2., 2.],\n",
    "     [3., 3.],\n",
    "     [4., 4.]\n",
    "    ]\n",
    ")\n",
    "\n",
    "pp.pprint(\"Mean: {}\".format(m.mean()))\n",
    "pp.pprint(\"Mean in the 0th dimension: {}\".format(m.mean(0)))\n",
    "pp.pprint(\"Mean in the 1st dimension: {}\".format(m.mean(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd77stQ5VQVT"
   },
   "source": [
    "#### concat操作\n",
    "\n",
    "`torch.cat`： 拼接tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "advfDCOPK9Gw",
    "outputId": "8efcab75-98f0-4562-a58f-fa419604956b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: torch.Size([4, 3])\n",
      "Shape after concatenation in dimension 0: torch.Size([12, 3])\n",
      "Shape after concatenation in dimension 1: torch.Size([4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate in dimension 0 and 1\n",
    "a_cat0 = torch.cat([a, a, a], dim=0)\n",
    "a_cat1 = torch.cat([a, a, a], dim=1)\n",
    "\n",
    "print(\"Initial shape: {}\".format(a.shape))\n",
    "print(\"Shape after concatenation in dimension 0: {}\".format(a_cat0.shape))\n",
    "print(\"Shape after concatenation in dimension 1: {}\".format(a_cat1.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BveswZMOjtff"
   },
   "source": [
    "#### inplace操作\n",
    "\n",
    "在操作名称后面加一个 underscore (`_`)，操作就变成了inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ebr7nn-DaU3B",
    "outputId": "aad366a1-1bbb-4864-8be0-46ef440763b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print our tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mP8-VtoHaKAc",
    "outputId": "94fafdfd-da16-4a94-bdd3-f9935a278ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add() is not in place\n",
    "a.add(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mY0ojINbaayp",
    "outputId": "cd396248-e6e4-4d0b-ebf9-5a7411f27882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12.],\n",
       "        [12., 12., 12.],\n",
       "        [12., 12., 12.],\n",
       "        [12., 12., 12.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_() is in place\n",
    "a.add_(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re8xiL37eAja"
   },
   "source": [
    "## Autograd & backprop\n",
    "\n",
    "`PyTorch`或者其他深度学习框架都包含自动微分功能。所以求梯度是不需要我们自己来做的。\n",
    "\n",
    "自动微分对应的操作是:\n",
    "\n",
    "`backward()`: 要求torch计算梯度，然后存到tensor的`grad`属性；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oEvBJHWfn8H",
    "outputId": "740dc424-2b22-4d2b-ac2a-6d45e06d914b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "# requires_grad parameter： 告诉torch我需要梯度\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "# Print the gradient if it is calculated\n",
    "# Currently None since x is a scalar\n",
    "pp.pprint(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTJazZXkgthP",
    "outputId": "e3d72745-0206-4c31-e11e-7b7ad833d5b5"
   },
   "outputs": [],
   "source": [
    "# 计算y 对 x 的梯度\n",
    "y = x * x * 3 # 3x^2\n",
    "y.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12.])\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(x.grad) # d(y)/d(x) = d(3x^2)/d(x) = 6x = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-8896bfb50d30>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  pp.pprint(y.grad) # 看看这里有啥问题！看下warning\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(y.grad) # 看看这里有啥问题！看下warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bad case: requires_grad=False\n",
    "# x = torch.tensor([2.], requires_grad=False)\n",
    "# pp.pprint(x.grad)\n",
    "\n",
    "# y = x * x * 3 # 3x^2\n",
    "# y.backward()\n",
    "# pp.pprint(x.grad)\n",
    "# pp.pprint(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Hqc2oM3iV6a"
   },
   "source": [
    "Let's run backprop from a different tensor again to see what happens.\n",
    "\n",
    "我们继续计算梯度，来看会有什么问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K--Az0Xiic_z",
    "outputId": "21195fa0-8466-4a33-92df-be40e3c33745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([48.])\n"
     ]
    }
   ],
   "source": [
    "# 跑多次试试有什么效果\n",
    "\n",
    "z = x * x * 3 # 3x^2\n",
    "z.backward()\n",
    "pp.pprint(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhjPkiE6i7ja"
   },
   "source": [
    "我们可以看到，“x.grad”被更新为迄今为止计算的梯度之和。当我们在神经网络中运行backprop时，在进行更新之前，我们将特定神经元的所有梯度相加。这也是为什么我们需要在每个训练迭代中运行`zero_grad()`的原因。否则，从一个训练迭代到另一个迭代，我们的梯度会不断增加，这会导致我们的更新错误。\n",
    "\n",
    "`zero_grad()`在项目中会用到。大家注意用在哪里。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYLWqKIoaOyd"
   },
   "source": [
    "## Neural Network Module\n",
    "\n",
    "到目前为止，我们已经研究了张量，以及其性质和基本运算。如果我们要从头开始构建网络的各个层，那么熟悉这些功能尤其有用。\n",
    "\n",
    "但接下来，我们将在`PyTorch`的`torch.nn`模块中使用预定义的块。然后我们将把这些块放在一起创建复杂的网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUmrDpbhV4Tn"
   },
   "outputs": [],
   "source": [
    "# 最流行的写法\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joGvRWjEbak0"
   },
   "source": [
    "### **Linear Layer**\n",
    "\n",
    "`nn.Linear(H_in, H_out)`: 线性层；输入形状： `(N, *, H_in)`； 输出形状： `(N, *, H_out)`；(`*`表示中间可以有任意多的维度和维数)。操作是`Ax+b`，其中`A` and `b`是随机初始化的。可以设置`bias=False`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XfnKI4-a5j9",
    "outputId": "867af230-5f0a-4b0b-c06c-025b1b8b0b0f"
   },
   "outputs": [],
   "source": [
    "# Create the inputs\n",
    "input = torch.ones(2,3,4)\n",
    "# N* H_in -> N*H_out\n",
    "\n",
    "\n",
    "# linear layers： transforming N,*,H_in inputs to N,*,H_out\n",
    "# dimensional outputs\n",
    "linear = nn.Linear(4, 2)\n",
    "nn.Linear(2,1)\n",
    "linear_output = linear(input)\n",
    "linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_9XKtAFYpdI",
    "outputId": "df248f31-e5ca-4857-88c2-c0bbc61a40be"
   },
   "outputs": [],
   "source": [
    "list(linear.parameters()) # Ax + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAXCCu9keUlW"
   },
   "source": [
    "### **Other Module Layers**\n",
    "\n",
    "`nn` module有很多方法可以使用，比如`nn.Conv2d`, `nn.BatchNorm1d`, `nn.LayerNorm`, etc。我们后面会看到很多例子。\n",
    "我们只需要记住的是，我们可以将这些层视为即插即用组件,我们只提供网络的维度维数信息。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yslDOK66fYWn"
   },
   "source": [
    "### **Activation Function Layer**\n",
    "\n",
    "激活函数： `nn.ReLU()`, `nn.Sigmoid()` and `nn.LeakyReLU()`等；Activation functions是elementwise的，所以输入与输出形状一致。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrJP5CveeOON",
    "outputId": "ce8b78e3-6311-44e2-c40c-f09f81f1acd1"
   },
   "outputs": [],
   "source": [
    "linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9v5FjQtd4Ck",
    "outputId": "966538af-4eac-475b-dd30-9174efd7ed3c"
   },
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(linear_output)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiYTthJwhEYT"
   },
   "source": [
    "### **Putting the Layers Together**\n",
    "\n",
    "我们可以根据这些基础模块来写自己设计的网络了。\n",
    "\n",
    "这里先介绍`nn.Sequentual`：让input依次经过一些网络操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtJeOqLxhBLY",
    "outputId": "b2370e4a-47bc-47f2-e784-d7fcd3ce57b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4368, 0.6556],\n",
       "         [0.4368, 0.6556],\n",
       "         [0.4368, 0.6556]],\n",
       "\n",
       "        [[0.4368, 0.6556],\n",
       "         [0.4368, 0.6556],\n",
       "         [0.4368, 0.6556]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "input = torch.ones(2,3,4)\n",
    "output = block(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkJ81p3GUVPM"
   },
   "source": [
    "### Custom Modules\n",
    "\n",
    "刚才我们的写法只是一次使用了linear+sigmoid的结构，还不能复用；\n",
    "\n",
    "我们有可能希望我们写的神经网络层能像nn中的模块一样，可以多次复用，而且和项目中数据处理的代码分离出来，形成模块化的代码。这是网络训练中必要的。\n",
    "\n",
    "所以，我们可以扩展`nn.Module`类，而不是使用预定义的模块来构建自己的模块。\n",
    "\n",
    "要创建自定义模块，我们首先要做的就是扩展`nn.module`。然后，我们可以在`__init__`函数中初始化参数，首先调用超级类的`__init__`函数。我们定义的所有类属性都是'nn'模块对象，在训练期间可以import进来进行学习。\n",
    "\n",
    "张量不是参数，但如果将张量封装在`nn.Parameter`类中，则可以将它们转换为模型参数。\n",
    "\n",
    "扩展`nn.Module`的所有类也都将实现一个`forward（x）`function，其中'x'是张量。这是传递给模块的参数时调用的函数，使用它是直接将模型实例像方法一样使用`model（x）`。这里涉及`__call__`。\n",
    "\n",
    "`__call__`： Python 类中一个非常特殊的实例方法，使得类实例对象可以像调用普通函数那样，以“对象名()”的形式使用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2P7eZiMj32_"
   },
   "outputs": [],
   "source": [
    "# 实现一个 MLP：\n",
    "\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    # 首先调用超级类的__init__函数\n",
    "    super(MultilayerPerceptron, self).__init__()\n",
    "\n",
    "    # 输入输出维数参数 parameters\n",
    "    self.input_size = input_size \n",
    "    self.hidden_size = hidden_size \n",
    "\n",
    "    # 定义我们的网络.\n",
    "    self.mlp = nn.Sequential(\n",
    "        nn.Linear(self.input_size, self.hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.hidden_size, self.input_size),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    output = self.mlp(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2DrfLiBVjNT"
   },
   "source": [
    "Here is an alternative way to define the same class. You can see that we can replace `nn.Sequential` by defining the individual layers in the `__init__` method and connecting the in the `forward` method. \n",
    "\n",
    "我们不一定要使用nn.Sequential：因为网络不全是像规范的单链表一样，有可能有分叉；（e.g., residual connection）。\n",
    "\n",
    "我们可以分别定义细粒度的网络操作；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "9-lqhsqwViIk"
   },
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    # Call to the __init__ function of the super class\n",
    "    super(MultilayerPerceptron, self).__init__()\n",
    "\n",
    "    # Bookkeeping: Saving the initialization parameters\n",
    "    self.input_size = input_size \n",
    "    self.hidden_size = hidden_size \n",
    "\n",
    "    # Defining of our layers\n",
    "    self.linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.linear2 = nn.Linear(self.hidden_size, self.input_size)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "  def forward(self, x):\n",
    "    linear = self.linear(x)\n",
    "    relu = self.relu(linear)\n",
    "    linear2 = self.linear2(relu)\n",
    "    output = self.sigmoid(linear2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQelcFo5bXgU"
   },
   "source": [
    "我们可以实例化和使用网络了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXi0T0FZbV0y",
    "outputId": "23547003-cfef-4a6d-e3f4-5fdb7a5cdd97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6426, 0.5003, 0.6154, 0.4535, 0.4123],\n",
       "        [0.6168, 0.4951, 0.5925, 0.4235, 0.4066]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a sample input\n",
    "input = torch.randn(2, 5)\n",
    "\n",
    "# Create our model\n",
    "model = MultilayerPerceptron(5, 3)\n",
    "\n",
    "# Pass our input through our model\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCCbjc-Fb2-B"
   },
   "source": [
    "We can inspect the parameters of our model with `named_parameters()` and `parameters()` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d23soYIb2WZ",
    "outputId": "3bf4243d-2f85-4593-8989-680b322aca13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2299,  0.1601,  0.1233, -0.1475,  0.0587],\n",
       "          [-0.0364,  0.3609, -0.0430,  0.3758,  0.3563],\n",
       "          [ 0.3821,  0.2915, -0.4395,  0.1851,  0.0661]], requires_grad=True)),\n",
       " ('linear.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.3389, 0.4166, 0.0383], requires_grad=True)),\n",
       " ('linear2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2364, -0.5334,  0.2881],\n",
       "          [ 0.3399, -0.0017,  0.3080],\n",
       "          [ 0.4521, -0.3788, -0.3862],\n",
       "          [ 0.5328, -0.4981,  0.2491],\n",
       "          [-0.4304, -0.2723,  0.3521]], requires_grad=True)),\n",
       " ('linear2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.5351, -0.0731,  0.3715, -0.3025, -0.2606], requires_grad=True))]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5JegycOdMFy"
   },
   "source": [
    "## Optimization\n",
    "\n",
    "网络的优化：计算梯度是一部分，但是网络参数还是没有更新，所以这时候需要优化器`torch.optim`了。\n",
    "\n",
    "`torch.optim`： 包含一些已经写好的优化器。比如：  `optim.SGD` and `optim.Adam`。（注意：BERT使用了AdamW，这个我们在后面课程会讲）。\n",
    "\n",
    "我们通过`model.parameters()`或者`model.named_parameters()`将模型参数传给优化器。\n",
    "\n",
    "优化器最重要的参数当然是： learning rate (`lr`) 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "W0F-TvV0kk-I"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgak6o5dlQWF"
   },
   "source": [
    "网络优化当然需要有一个优化的目标：`loss`。\n",
    "\n",
    "`nn`中有损失函数可以选择（such as `nn.BCELoss()`），当然，我们可以选择自己写。比如，我们后面会实现focal loss。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGYFiaT_vXBn",
    "outputId": "48bd9b70-f225-4c20-fad7-5f7a6fa4ed9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 5])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the y data\n",
    "y = torch.ones(1000, 5)\n",
    "\n",
    "# Add some noise to our goal y to generate our x\n",
    "# We want out model to predict our original data, albeit the noise\n",
    "x = y + torch.randn_like(y)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEsiOdpWvfLj"
   },
   "source": [
    "Now, we can define our model, optimizer and the loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oA2XsdsbN8p",
    "outputId": "b4cd8c6c-d2e9-4594-f238-234d61e027d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7418498992919922"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = MultilayerPerceptron(5, 3)\n",
    "\n",
    "# Define the optimizer\n",
    "adam = optim.Adam(model.parameters(), lr=1e-1)\n",
    "\n",
    "# Define loss using a predefined loss function\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "# Calculate how our model is doing now\n",
    "y_pred = model(x)\n",
    "loss_function(y_pred, y).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtxU7Y8ZufSR"
   },
   "source": [
    "training 过程：每一轮中，将数据给模型，可以是分批给，然后不断更新参数，反复多次。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogl6-Ctmuek6",
    "outputId": "b22f36a0-c702-4c89-e5d4-27c60d27c0ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: traing loss: 0.7418498992919922\n",
      "Epoch 1: traing loss: 0.6527495384216309\n",
      "Epoch 2: traing loss: 0.530566394329071\n",
      "Epoch 3: traing loss: 0.3904207944869995\n",
      "Epoch 4: traing loss: 0.2569248676300049\n",
      "Epoch 5: traing loss: 0.15106557309627533\n",
      "Epoch 6: traing loss: 0.08078690618276596\n",
      "Epoch 7: traing loss: 0.04125015437602997\n",
      "Epoch 8: traing loss: 0.021573727950453758\n",
      "Epoch 9: traing loss: 0.011932962574064732\n",
      "Epoch 10: traing loss: 0.0071051171980798244\n",
      "Epoch 11: traing loss: 0.0046133920550346375\n",
      "Epoch 12: traing loss: 0.0031928708776831627\n",
      "Epoch 13: traing loss: 0.0023333963472396135\n",
      "Epoch 14: traing loss: 0.001775500481016934\n",
      "Epoch 15: traing loss: 0.001396326581016183\n",
      "Epoch 16: traing loss: 0.0011346820974722505\n",
      "Epoch 17: traing loss: 0.0009461692534387112\n",
      "Epoch 18: traing loss: 0.000804872892331332\n",
      "Epoch 19: traing loss: 0.0006984971114434302\n",
      "Epoch 20: traing loss: 0.000617033161688596\n",
      "Epoch 21: traing loss: 0.0005527936737053096\n",
      "Epoch 22: traing loss: 0.0005011251196265221\n",
      "Epoch 23: traing loss: 0.000458730646641925\n",
      "Epoch 24: traing loss: 0.0004233582876622677\n",
      "Epoch 25: traing loss: 0.00039343745447695255\n",
      "Epoch 26: traing loss: 0.00036594836274161935\n",
      "Epoch 27: traing loss: 0.00033668955438770354\n",
      "Epoch 28: traing loss: 0.0003117485612165183\n",
      "Epoch 29: traing loss: 0.0002906489244196564\n",
      "Epoch 30: traing loss: 0.00027267663972452283\n",
      "Epoch 31: traing loss: 0.00025725929299369454\n",
      "Epoch 32: traing loss: 0.00024393365310970694\n",
      "Epoch 33: traing loss: 0.0002323389780940488\n",
      "Epoch 34: traing loss: 0.0002221739268861711\n",
      "Epoch 35: traing loss: 0.00021320651285350323\n",
      "Epoch 36: traing loss: 0.00020525553554762155\n",
      "Epoch 37: traing loss: 0.00019816476560663432\n",
      "Epoch 38: traing loss: 0.0001918064517667517\n",
      "Epoch 39: traing loss: 0.00018607360834721476\n",
      "Epoch 40: traing loss: 0.00018087959324475378\n",
      "Epoch 41: traing loss: 0.0001761513267410919\n",
      "Epoch 42: traing loss: 0.00017182764713652432\n",
      "Epoch 43: traing loss: 0.00016785733168944716\n",
      "Epoch 44: traing loss: 0.00016419668099842966\n",
      "Epoch 45: traing loss: 0.00016080871864687651\n",
      "Epoch 46: traing loss: 0.00015766185242682695\n",
      "Epoch 47: traing loss: 0.0001547283463878557\n",
      "Epoch 48: traing loss: 0.00015198509208858013\n",
      "Epoch 49: traing loss: 0.00014941158588044345\n",
      "Epoch 50: traing loss: 0.00014698985614813864\n",
      "Epoch 51: traing loss: 0.00014470447786152363\n",
      "Epoch 52: traing loss: 0.0001425421651219949\n",
      "Epoch 53: traing loss: 0.0001404903014190495\n",
      "Epoch 54: traing loss: 0.00013853871496394277\n",
      "Epoch 55: traing loss: 0.00013667829625774175\n",
      "Epoch 56: traing loss: 0.0001349003432551399\n",
      "Epoch 57: traing loss: 0.0001331977400695905\n",
      "Epoch 58: traing loss: 0.00013156389468349516\n",
      "Epoch 59: traing loss: 0.00012999321916140616\n",
      "Epoch 60: traing loss: 0.00012848015467170626\n",
      "Epoch 61: traing loss: 0.00012702029198408127\n",
      "Epoch 62: traing loss: 0.00012560929462779313\n",
      "Epoch 63: traing loss: 0.00012424301530700177\n",
      "Epoch 64: traing loss: 0.00012291906750760972\n",
      "Epoch 65: traing loss: 0.00012163368228357285\n",
      "Epoch 66: traing loss: 0.00012038384738843888\n",
      "Epoch 67: traing loss: 0.00011916763469344005\n",
      "Epoch 68: traing loss: 0.00011798268678830937\n",
      "Epoch 69: traing loss: 0.00011682702461257577\n",
      "Epoch 70: traing loss: 0.00011569843627512455\n",
      "Epoch 71: traing loss: 0.00011459543748060241\n",
      "Epoch 72: traing loss: 0.00011351633293088526\n",
      "Epoch 73: traing loss: 0.00011246006761211902\n",
      "Epoch 74: traing loss: 0.00011142537550767884\n",
      "Epoch 75: traing loss: 0.0001104105613194406\n",
      "Epoch 76: traing loss: 0.00010941526852548122\n",
      "Epoch 77: traing loss: 0.00010843797645065933\n",
      "Epoch 78: traing loss: 0.00010747803753474727\n",
      "Epoch 79: traing loss: 0.00010653454955900088\n",
      "Epoch 80: traing loss: 0.00010560674854787067\n",
      "Epoch 81: traing loss: 0.00010469442349858582\n",
      "Epoch 82: traing loss: 0.00010379619925515726\n",
      "Epoch 83: traing loss: 0.00010291182843502611\n",
      "Epoch 84: traing loss: 0.00010204094724031165\n",
      "Epoch 85: traing loss: 0.000101182893558871\n",
      "Epoch 86: traing loss: 0.00010033715807367116\n",
      "Epoch 87: traing loss: 9.950347885023803e-05\n",
      "Epoch 88: traing loss: 9.868117922451347e-05\n",
      "Epoch 89: traing loss: 9.787025192053989e-05\n",
      "Epoch 90: traing loss: 9.707016579341143e-05\n",
      "Epoch 91: traing loss: 9.628054249333218e-05\n",
      "Epoch 92: traing loss: 9.550115646561608e-05\n",
      "Epoch 93: traing loss: 9.473168756812811e-05\n",
      "Epoch 94: traing loss: 9.397217218065634e-05\n",
      "Epoch 95: traing loss: 9.322189725935459e-05\n",
      "Epoch 96: traing loss: 9.248108108295128e-05\n",
      "Epoch 97: traing loss: 9.174908336717635e-05\n",
      "Epoch 98: traing loss: 9.102602052735165e-05\n",
      "Epoch 99: traing loss: 9.031142690218985e-05\n"
     ]
    }
   ],
   "source": [
    "# Set the number of epoch, which determines the number of training iterations\n",
    "n_epoch = 100\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  # Set the gradients to 0\n",
    "  adam.zero_grad()\n",
    "\n",
    "  # Get the model predictions\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # Get the loss\n",
    "  loss = loss_function(y_pred, y)\n",
    "\n",
    "  # Print stats\n",
    "  print(f\"Epoch {epoch}: traing loss: {loss}\")\n",
    "\n",
    "  # Compute the gradients\n",
    "  loss.backward()\n",
    "\n",
    "  # Take a step to optimize the weights\n",
    "  adam.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrMJ8AmqeCY-",
    "outputId": "73815ecf-9630-4273-9cbb-516258bafe10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1.9180,  1.3026,  1.4166,  1.2837,  0.1992],\n",
       "         [ 1.5523,  1.7444,  1.1611,  1.4998,  1.2552],\n",
       "         [ 1.5084,  1.2855,  1.7644,  0.3926,  0.7827]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.6776, 1.5555, 1.6371], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[1.5044, 1.5184, 1.9674],\n",
       "         [2.2033, 1.6009, 2.2161],\n",
       "         [1.8232, 2.0888, 2.2699],\n",
       "         [1.6227, 1.6755, 1.3923],\n",
       "         [2.0391, 1.9366, 1.8840]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.3140, 1.5559, 1.0383, 1.8267, 0.9656], requires_grad=True)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nXApd82wlsF"
   },
   "source": [
    "You can see that our loss is decreasing. Let's check the predictions of our model now and see if they are close to our original `y`, which was all `1s`. \n",
    "\n",
    "我们来做下推理：看给出预测结果，看是否和原来的一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRqE7P9EtvuS",
    "outputId": "d4c76a74-0568-43a9-da28-f25340b87e7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how our model performs on the training data\n",
    "y_pred = model(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS224N PyTorch Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
